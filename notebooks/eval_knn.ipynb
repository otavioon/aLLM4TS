{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772368ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "from data_provider.data_loader import DAGHAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f570bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_data_path = Path(\n",
    "    \"/workspaces/HIAAC-KR-Dev-Container/some_datasets/DAGHAR/standardized_view\"\n",
    ")\n",
    "\n",
    "datasets = [\n",
    "    \"KuHar\",\n",
    "    \"MotionSense\",\n",
    "    \"RealWorld_thigh\",\n",
    "    \"RealWorld_waist\",\n",
    "    \"UCI\",\n",
    "    \"WISDM\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2209b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2021\n",
    "train_datasets = defaultdict(dict)\n",
    "test_datasets = dict()\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "    for percent in [1, 10, 50, 100]:\n",
    "        print(f\"Dataset: {dataset}, Percent: {percent}\")\n",
    "        train_datasets[dataset][percent] = DAGHAR(\n",
    "            root_path=root_data_path / dataset,\n",
    "            flag=\"train\",\n",
    "            perform_instance_norm=True,\n",
    "            percent=percent,\n",
    "            seed=seed\n",
    "        )\n",
    "        \n",
    "    print(f\"Dataset: {dataset}, Test\")\n",
    "    test_datasets[dataset] = DAGHAR(\n",
    "        root_path=root_data_path / dataset,\n",
    "        flag=\"test\",\n",
    "        perform_instance_norm=True,\n",
    "        percent=100,\n",
    "        seed=seed\n",
    "    )\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecadc953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(dataset):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(dataset)):\n",
    "        X, y = dataset[i]\n",
    "        Xs.append(X)\n",
    "        ys.append(y)\n",
    "    Xs = np.array(Xs)\n",
    "    ys = np.array(ys).astype(np.int64)\n",
    "    return Xs, ys\n",
    "\n",
    "\n",
    "def parse_path_name(root_path: Path):\n",
    "    path = root_path.name    \n",
    "    return {\n",
    "        \"name\": path,\n",
    "        \"path\": str(root_path),\n",
    "        \"dataset_name\": path.split(\"_patch\")[0].strip(),\n",
    "        \"patch_size\": path.split(\"_patch-\")[1].split(\"_\")[0].strip(),\n",
    "        \"stride\": path.split(\"_stride-\")[1].split(\"_\")[0].strip(),\n",
    "        \"pretrain_dataset\": path.split(\"_aLLM4TS-\")[1].split(\"_\")[0].strip(),\n",
    "        \"normalization\": path.split(\"_norm-\")[1].split(\"_\")[0].strip(),\n",
    "        \"percent\": int(path.split(\"_percent-\")[1].split(\"_\")[0].strip()),\n",
    "        \"ft_strategy\": path.split(\"_freeze-\")[1].split(\"_\")[0].strip(),\n",
    "        \"head\": path.split(\"_head-\")[1].split(\"_\")[0] if \"_head-\" in path else \"aLLM4TS\",\n",
    "    }  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d83bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpts_path = Path(\"/workspaces/HIAAC-KR-Dev-Container/workspace/aLLM4TS/checkpoints/classification\")\n",
    "\n",
    "ckpts = [\n",
    "    parse_path_name(ckpt) for ckpt in ckpts_path.iterdir()\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(ckpts)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16214a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df[\"normalization\"] == \"yes\")].reset_index(drop=True)\n",
    "df.sort_values(by=\"percent\", ascending=False, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709aa65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "results = []\n",
    "results_csv_path = \"allmt4s_results_knn.csv\"\n",
    "\n",
    "for row_index, line in tqdm(df.iterrows(), desc=\"Processing models\", total=len(df)):\n",
    "    train_dataset = train_datasets[line[\"dataset_name\"]][line[\"percent\"]]\n",
    "    test_dataset = test_datasets[line[\"dataset_name\"]]\n",
    "    X_train, y_train = get_dataset(train_dataset)\n",
    "    X_test, y_test = get_dataset(test_dataset)\n",
    "    \n",
    "    y_train = np.expand_dims(y_train, axis=1)\n",
    "    y_test = np.expand_dims(y_test, axis=1)\n",
    "    \n",
    "    name = line[\"name\"]\n",
    "    root_path = Path(line[\"path\"])\n",
    "    for train_embedding_path in root_path.rglob(\"train_projections_before_training.npy\"):\n",
    "        test_embedding_path = train_embedding_path.parent / \"test_projections_before_training.npy\"\n",
    "        exp_no = int(train_embedding_path.parent.name.split(\"_exp_\")[1])\n",
    "        # print(f\"Dataset: {line['dataset_name']}, Percent: {line['percent']}, Exp: {exp_no}, Embedding: {train_embedding_path}\")\n",
    "        train_embeddings = np.load(train_embedding_path)\n",
    "        test_embeddings = np.load(test_embedding_path)\n",
    "        # print(f\"Train Embedding Shape: {train_embeddings.shape}\")\n",
    "        # print(f\"Test Embedding Shape: {test_embeddings.shape}\")\n",
    "        \n",
    "        # for n_neighorns in [2, 3, 5]:\n",
    "        for n_neighorns in [2, 3, 5]:\n",
    "            result_dict = line.to_dict()\n",
    "            result_dict[\"train_embedding\"] = str(train_embedding_path)\n",
    "            result_dict[\"test_embedding\"] = str(train_embedding_path.parent / \"test_projections_before_training.npy\")\n",
    "            result_dict[\"n_neighbors\"] = n_neighorns\n",
    "            result_dict[\"exp_no\"] = exp_no\n",
    "            \n",
    "            knn = KNeighborsClassifier(n_neighbors=n_neighorns)\n",
    "            # print(f\"Train embedding shape: {train_embeddings.shape}, y_train shape: {y_train.shape}\")\n",
    "            # print(f\"Test embedding shape: {test_embeddings.shape}, y_test shape: {y_test.shape}\")\n",
    "            \n",
    "            knn.fit(train_embeddings, y_train)\n",
    "            y_pred = knn.predict(test_embeddings)\n",
    "            score = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            result_dict[\"accuracy\"] = score\n",
    "            results.append(result_dict)\n",
    "            # print(f\"Accuracy: {score}\")\n",
    "            # print()\n",
    "            \n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df.to_csv(results_csv_path, index=False)\n",
    "        # print(f\"Results saved to {results_csv_path}\")\n",
    "        # print()            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
