{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/_distutils_hack/__init__.py:53: UserWarning: Reliance on distutils from stdlib is deprecated. Users must rely on setuptools to provide the distutils module. Avoid importing distutils or import setuptools first, and avoid setting SETUPTOOLS_USE_DISTUTILS=stdlib. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from minerva.models.ssl.tfc import TFC_Model\n",
    "from minerva.models.nets.tfc import TFC_Backbone\n",
    "from minerva.models.nets.tnc import TSEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from utils.timefeatures import time_features\n",
    "import warnings\n",
    "import lightning as L\n",
    "from torch.utils.data import DataLoader\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFC_Model(\n",
       "  (backbone): TFC_Backbone(\n",
       "    (time_encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (frequency_encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (time_projector): TFC_Standard_Projector(\n",
       "      (projector): Sequential(\n",
       "        (0): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        (1): IgnoreWhenBatch1(\n",
       "          (module): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (frequency_projector): TFC_Standard_Projector(\n",
       "      (projector): Sequential(\n",
       "        (0): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        (1): IgnoreWhenBatch1(\n",
       "          (module): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (loss_fn): NTXentLoss_poly(\n",
       "    (softmax): Softmax(dim=-1)\n",
       "    (_cosine_similarity): CosineSimilarity()\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "input_channels = 1\n",
    "TS_length = 1024\n",
    "num_classes = 1\n",
    "\n",
    "# model = TFC_Model(\n",
    "#     input_channels=input_channels,\n",
    "#     batch_size=batch_size,\n",
    "#     TS_length=TS_length,\n",
    "#     num_classes=None,\n",
    "#     batch_1_correction=True,\n",
    "#     backbone=TFC_Backbone(\n",
    "#         input_channels=input_channels,\n",
    "#         TS_length=TS_length,\n",
    "#         time_encoder=TSEncoder(\n",
    "#             input_dims=input_channels,\n",
    "#             output_dims=64,\n",
    "#             hidden_dims=64,\n",
    "#             depth=10,\n",
    "#             permute=True,\n",
    "#         ),\n",
    "#         frequency_encoder=TSEncoder(\n",
    "#             input_dims=input_channels,\n",
    "#             output_dims=64,\n",
    "#             hidden_dims=64,\n",
    "#             depth=10,\n",
    "#             permute=True,\n",
    "#         ),\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "# model\n",
    "\n",
    "\n",
    "# model = TFC_Model(input_channels=input_channels, TS_length=TS_length, batch_1_correction=True, batch_size=batch_size)\n",
    "\n",
    "model = TFC_Model(\n",
    "    input_channels=input_channels,\n",
    "    batch_size=batch_size,\n",
    "    TS_length=TS_length,\n",
    "    num_classes=None,\n",
    "    batch_1_correction=True,\n",
    "    backbone=TFC_Backbone(\n",
    "        input_channels=input_channels,\n",
    "        TS_length=TS_length,\n",
    "        time_encoder=TransformerEncoder(\n",
    "            TransformerEncoderLayer(\n",
    "                d_model=TS_length, dim_feedforward=2*128, nhead=2\n",
    "            ),\n",
    "            num_layers=2,\n",
    "        ),\n",
    "        frequency_encoder=TransformerEncoder(\n",
    "            TransformerEncoderLayer(\n",
    "                d_model=TS_length, dim_feedforward=2*128, nhead=2\n",
    "            ),\n",
    "            num_layers=2,\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_pretrain(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        pt_data=\"ETTh1_ETTm1_ETTh2_ETTm2_weather_traffic_electricity_illness\",\n",
    "        patch_len=16,\n",
    "        stride=16,\n",
    "        root_path=\"/workspaces/HIAAC-KR-Dev-Container/workspace/aLLM4TS/dataset/\",\n",
    "        flag=\"train\",\n",
    "        size=[1024, 0, 1024],\n",
    "        features=\"M\",\n",
    "        data_path=\"ETTh1.csv\",\n",
    "        target=\"OT\",\n",
    "        scale=True,\n",
    "        timeenc=1,\n",
    "        freq=\"h\",\n",
    "        percent=100,\n",
    "    ):\n",
    "\n",
    "        self.pt_data = pt_data\n",
    "        self.patch_len = patch_len\n",
    "        self.stride = stride\n",
    "        if size == None:\n",
    "            raise NotImplementedError\n",
    "        else:\n",
    "            self.seq_len = size[0]\n",
    "            self.label_len = size[1]\n",
    "            self.pred_len = size[2]\n",
    "\n",
    "        assert flag in [\"train\", \"test\", \"val\"]\n",
    "        type_map = {\"train\": 0, \"val\": 1, \"test\": 2}\n",
    "        self.set_type = type_map[flag]\n",
    "\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.scale = scale\n",
    "        self.timeenc = timeenc\n",
    "        self.freq = freq\n",
    "        self.percent = percent\n",
    "\n",
    "        self.root_path = root_path\n",
    "        self.data_path = data_path\n",
    "        self.__read_data__()\n",
    "\n",
    "    def __read_data__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        pt_datasets = self.pt_data.split(\"_\")\n",
    "\n",
    "        data_list = []\n",
    "        data_stamp_list = []\n",
    "        for pt_dataset in pt_datasets:\n",
    "            df_raw = pd.read_csv(\n",
    "                os.path.join(self.root_path, f\"{pt_dataset}.csv\")\n",
    "            )\n",
    "            dataset_len = len(df_raw)\n",
    "            if \"ETTh\" in pt_dataset:\n",
    "                border1s = [\n",
    "                    0,\n",
    "                    12 * 30 * 24 - self.seq_len,\n",
    "                    12 * 30 * 24 + 4 * 30 * 24 - self.seq_len,\n",
    "                ]\n",
    "                border2s = [\n",
    "                    12 * 30 * 24,\n",
    "                    12 * 30 * 24 + 4 * 30 * 24,\n",
    "                    12 * 30 * 24 + 8 * 30 * 24,\n",
    "                ]\n",
    "                border1 = border1s[self.set_type]\n",
    "                border2 = border2s[self.set_type]\n",
    "            elif \"ETTm\" in pt_dataset:\n",
    "                border1s = [\n",
    "                    0,\n",
    "                    12 * 30 * 24 * 4 - self.seq_len,\n",
    "                    12 * 30 * 24 * 4 + 4 * 30 * 24 * 4 - self.seq_len,\n",
    "                ]\n",
    "                border2s = [\n",
    "                    12 * 30 * 24 * 4,\n",
    "                    12 * 30 * 24 * 4 + 4 * 30 * 24 * 4,\n",
    "                    12 * 30 * 24 * 4 + 8 * 30 * 24 * 4,\n",
    "                ]\n",
    "                border1 = border1s[self.set_type]\n",
    "                border2 = border2s[self.set_type]\n",
    "            else:\n",
    "                num_train = int(dataset_len * 0.7)\n",
    "                num_test = int(dataset_len * 0.2)\n",
    "                num_vali = dataset_len - num_train - num_test\n",
    "                border1s = [\n",
    "                    0,\n",
    "                    num_train - self.seq_len,\n",
    "                    dataset_len - num_test - self.seq_len,\n",
    "                ]\n",
    "                border2s = [num_train, num_train + num_vali, dataset_len]\n",
    "                border1 = border1s[self.set_type]\n",
    "                border2 = border2s[self.set_type]\n",
    "            if self.set_type == 0:\n",
    "                border2 = (\n",
    "                    border2 - self.seq_len\n",
    "                ) * self.percent // 100 + self.seq_len\n",
    "            if self.features == \"M\" or self.features == \"MS\":\n",
    "                cols_data = df_raw.columns[1:]\n",
    "                df_data = df_raw[cols_data]\n",
    "            elif self.features == \"S\":\n",
    "                df_data = df_raw[[self.target]]\n",
    "\n",
    "            df_data = df_data.values\n",
    "\n",
    "            if self.scale:\n",
    "                train_data = df_data[border1s[0] : border2s[0]]\n",
    "                self.scaler.fit(train_data)\n",
    "                data = self.scaler.transform(df_data)\n",
    "            else:\n",
    "                data = df_data\n",
    "\n",
    "            data = data[border1:border2]\n",
    "            data = data.reshape((len(data) * len(cols_data), 1))\n",
    "            df_stamp = df_raw[[\"date\"]][border1:border2]\n",
    "            df_stamp[\"date\"] = pd.to_datetime(df_stamp.date)\n",
    "            if self.timeenc == 0:\n",
    "                df_stamp[\"month\"] = df_stamp.date.apply(\n",
    "                    lambda row: row.month, 1\n",
    "                )\n",
    "                df_stamp[\"day\"] = df_stamp.date.apply(lambda row: row.day, 1)\n",
    "                df_stamp[\"weekday\"] = df_stamp.date.apply(\n",
    "                    lambda row: row.weekday(), 1\n",
    "                )\n",
    "                df_stamp[\"hour\"] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
    "                data_stamp = df_stamp.drop([\"date\"], axis=1).values\n",
    "            elif self.timeenc == 1:\n",
    "                data_stamp = time_features(\n",
    "                    pd.to_datetime(df_stamp[\"date\"].values), freq=self.freq\n",
    "                )\n",
    "                data_stamp = data_stamp.transpose(1, 0)\n",
    "\n",
    "            data_list.append(data)\n",
    "            df_stamp = np.array(\n",
    "                [data_stamp for i in range(len(cols_data))]\n",
    "            ).reshape((len(data_stamp) * len(cols_data), 4))\n",
    "            data_stamp_list.append(df_stamp)\n",
    "\n",
    "        self.data = np.concatenate(data_list, axis=0)\n",
    "        self.data_stamp = np.concatenate(data_stamp_list, axis=0)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        s_begin = index\n",
    "        s_end = s_begin + self.seq_len\n",
    "        r_begin = s_begin + self.stride\n",
    "        r_end = s_end + self.stride\n",
    "\n",
    "        seq_x = self.data[s_begin:s_end].swapaxes(0, 1)\n",
    "        seq_y = self.data[r_begin:r_end].swapaxes(0, 1)\n",
    "        return seq_x, seq_y\n",
    "        # seq_x_mark = self.data_stamp[s_begin:s_end]\n",
    "        # seq_y_mark = self.data_stamp[r_begin:r_end]\n",
    "\n",
    "        # return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.seq_len - self.patch_len + 1\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        return self.scaler.inverse_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset_pretrain(flag=\"train\")\n",
    "val_dataset = Dataset_pretrain(flag=\"val\")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filename=\"tfc-{epoch:02d}\",\n",
    "        every_n_epochs=1,\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        patience=50,\n",
    "        verbose=True,\n",
    "        monitor=\"val_loss\",\n",
    "    )\n",
    "]\n",
    "\n",
    "logger = CSVLogger(save_dir=\"logs\", name=\"tfc-transformer\")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=100,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    callbacks=callbacks,\n",
    "    logger=logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type            | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | backbone | TFC_Backbone    | 19.5 M | train\n",
      "1 | loss_fn  | NTXentLoss_poly | 0      | train\n",
      "-----------------------------------------------------\n",
      "19.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "19.5 M    Total params\n",
      "78.015    Total estimated model params size (MB)\n",
      "63        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 583/139677 [01:30<6:01:01,  6.42it/s, v_num=4]   "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# batch_x, batch_y = next(iter(train_dataloader))\n",
    "# batch_x.shape, batch_y.shape\n",
    "\n",
    "trainer.fit(\n",
    "    model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
